# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F84BFtOWzgqxxnAzVmTZsamkhj53DmOt
"""

pip install streamlit

import streamlit as st

import os

import langchain

pip install langchain_community

pip install langchain_google_genai

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings , ChatGoogleGenerativeAI

pip install langchain_chroma

from langchain_chroma import Chroma

pip install langchain.vectorstores

from langchain.vectorstores import Pinecone

pip install langchain_pinecone

from langchain_pinecone import PineconeVectorStore

pip install langchain.chains

from langchain.chains import create_retrieval_chain

pip install langchain.chains.combine_documents

from langchain.chains.combine_documents import create_stuff_documents_chain

pip install langchain_core.prompts

from langchain_core.prompts import ChatPromptTemplate

pip install dotenv

from dotenv import load_dotenv

load_dotenv()

PINECONE_INDEX_NAME = "firstproject"
os.environ["PINECONE_API_KEY"]="pcsk_4u81nL_31P8DCTTWg8sh2o3QF4KPb54gjac1CHmaYBJWXWAFaKFjtuwNd4sTNfwckkYE8j"
st.title=("YOLOVO Q&A Application")

pip install PyPDF

from langchain_community.document_loaders import PyPDFLoader

loader=PyPDFLoader("yolov9_paper.pdf")

data=loader.load()

text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000)

docs=text_splitter.split_documents(data)

embeddings=GoogleGenerativeAIEmbeddings(model="models/embedding-001")

docsearch=Pinecone.from_existing_index(index_name=PINECONE_INDEX_NAME,embedding=embeddings)

docsearch=PineconeVectorStore.from_existing_index(index_name=PINECONE_INDEX_NAME,embedding=embeddings)

from re import search
retriever=docsearch.as_retriever(search_type="similarity",search_kwargs={"k":10})

llm=ChatGoogleGenerativeAI(model="gemini-1.5-pro",temperature=0,max_tokens=None,timeout=None)

query=st.chat_input("Enter your query")
prompt=query

system_prompt=(
    "You are an assistant for question-answering tasks."
    "Use the following pieces of retrieved context to answer"
    "the question. If you don't know the answer, say that you "
    "don't know. Use three sentences maximum and keep the "
    "answer concise"
    "\n\n"
    "{context}"
)

prompt=ChatPromptTemplate.from_messages(
    [
        ("system",system_prompt),
        ("human","{input}"),
    ]
)

if query:
  question_answer_chain=create_stuff_documents_chain(llm,prompt)
  rag_chain=create_retrieval_chain(retriever,question_answer_chain)
  response=rag_chain.invoke({"input":query})
  st.write(response["answer"])

!pip install -q condacolab
   import condacolab
   condacolab.install()

import condacolab
condacolab.check()

!conda create -n myenv python=3.8
!conda activate myenv
!conda install -c conda-forge numpy

!conda init

!conda init langchain

!conda activate langchain

!streamlit run app.py

